{
    "collab_server" : "",
    "contents" : "---\ntitle: \"EDA\"\nauthor: \"Liliana Millán, liliana.millan@gmail.com\"\ndate: \"September 2017\"\noutput: \n  html_document:\n    df_print: paged\n    highlight: tango\n    theme: lumen\n---\n\n![](../images/itam_logo.png)\n\n## Agenda  {.tabset .tabset-fade .tabset-pills}\n\n+ EDA\n  + Tipos de EDA\n  + Visualizaciones incorrectas\n+ Gráficas\n+ Formas deseables de datos\n+ Casos de estudio\n\nEstas notas estan basadas en el libro *Graphical Data Analysis with R*, la bibliografía se encuentra en el temario\n\n\n### Exploratory Data Analysis\n\nEs el PRIMER paso en el análisis de datos, es un punto CRÍTICO para realizar un análisis correcto -con contexto, sin sesgo, desde diferentes puntos de vista-\n\nPuedes pensarlo como la primera aproximación al problema que quieres resolver\n\n#### Objetivos \n\n+ Detectar de errores \n+ Detectar de datos anómalos, faltantes \n+ Detectar de datos aislados \n+ Verficar de que tienes datos relevantes y suficientes para contestar tu(s) pregunta(s)\n+ Verificar si la(s) pregunta(s) es la correcta\n   + ¿se requiren más datos?\n+ ¿Qué otras variables puedes obtener de este set de datos que te permitan contestar tu(s) pregunta(s)? $\\rightarrow$ lo veremos en feature extraction / feature selection\n+ Verificar de suposiciones -tuyas-\n+ Selección preliminar de los modelos apropiados \n+ Determinar relaciones entre las variables explicativas\n+ Evaluar la dirección y tamaño -aproximado- de las relaciones entre las variables explicativas y la(s) variable(s) de salida -variable target-\n+ Empezar a visualizar cómo sería la respuesta a la(s) pregunta(s) que quieres contestar con este set de datos\n+ También nos ayudará cuando querramos automatizar la evaluación y tuneo de modelos\n\n![](../images/pointer.png) Como verás ayuda a hacer un modelado más robusto\n\n![](../images/pointer.png) De manera no estricta, si un análisis de datos no incluye modelado estadístico formal y/o inferencia/predicción entonces el análisis es EDA\n\n#### Tipos de EDA \n\nNormalmente los datos que tenemos para analizar vienen en un formato rectangular (..aunque nunca limpios ni cómo los necesitamos (╯°□°)╯︵ ┻━┻, pero lo veremos más adelante) donde un renglón es una observación de un *experimento* y cada columna es: el identificador del sujeto, la variable de salida y las variables explicativas.\n\nAnalizar los datos de esta *tabla* resulta tedioso, aburrido y abrumador de entender, *enter EDA* :), las técnicas utilizadas en el EDA permiten esconder ciertas cosas de los datos para hacer sobresalir o dejar claras otras.\n\nHay 2 grandes maneras cruzadas de clasificar el tipo de EDA: \n\n1. Hacerlo de manera gŕafica o no -GEDA Graphical Exploratory Data Analysis, EDA Exploratory Data Analysis-\n2. Cada método es univariado o multivariado -nonrmalmente bivariada-\n\n\n+ **Análisis exploratorio no gráfico:** Generalmente incluye calcular el resúmen estadístico de \n+ **Análisis exploratorio gráfico:** Resúmen los datos de forma gráfica \n+ **Univariada:** Analizan una variable a la vez \n+ **Multivariada:** Analizan 2 o más variables a la vez para explorar relaciones entre variables -normalmente bivariada-\n\n![](../images/pointer.png) Se recomienda primero hacer un EDA univariado a cada variable que forme parte de un EDA multivariado ANTES de hacer el EDA multivariado\n\nDespués de clasificar en estos 4 tipos cruzados existen más divisiones al EDA basadas en: \n\na. El **rol de la variable**: salida o explicativa\nb. El **tipo de la variable**: categórica o numérica \n\n\n#### Algunos consejos\n\n+ Sí existen guías para qué técnica de EDA utilizar dependiendo de las circunstancias, pero normalmente eso se va mejorando con la experiencia\n+ No existe un tipo óptimo de gráfica, prueba varias $\\rightarrow$ aunque si hay reglas que debes seguir para la visualización\n+ Antes de ponerte a hacer gráficas piensa qué quieres visualizar y por qué\n\n#### Ejemplos de lo que NO debes hacer en visualizaciones\n\n+ NO Graficar pies! ¿por qué? \n\nAunque es una visualización muy solicitada por gente de negocio, existe una mejor manera de representar la misma información. El objetivo de una visualización de pie es mostrar cómo un 100% se distribuye entre diferentes valores de una variable. Una mejor manera de visualizar la misma información es haciendo una grfáica de barras horizontales ordenando de la proporción más grande a la más pequeña, el eje x tiene que ir de 0 a 100%.\n\n```{r echo=F, warning=F, error=F, message=F}\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(knitr)\nlibrary(dplyr)\n\n\ndf <- data.frame(departamento=c(\"ventas\",\"adquisiciones\",\"rh\",\"ti\",\"finanzas\",\"atencion_clientes\",\"contabilidad\"), \n                 prop=c(1,3,4,5,7,20,60))\n\ndf$departamento <- factor(df$departamento, levels=c(\"ventas\",\"adquisiciones\",\"rh\",\"ti\",\"finanzas\",\"atencion_clientes\",\"contabilidad\"))\n\n\nggplot(df, aes( x=\"\",y=prop, fill=departamento)) +\n  geom_bar(width=1, stat=\"identity\") +\n  coord_polar(\"y\", start=0) + \n  theme_bw() \n\n\nggplot(df, aes(y=prop, x=departamento, fill=departamento)) +\n  geom_bar(stat=\"identity\") +\n  coord_flip() +\n  theme_bw() +\n  scale_y_continuous(limits=c(0,100))\n\n\n```\n\n\nSi no te queda de otra más que presentar un pie, asegúrate que las proporciones suman 100%!, ordena las divisiones de mayor a menor...\n\n¿Algo malo aquí?\n\n![](../images/fake_data_visualizations_1.png)\n\n\\* Imagen tomada de [flowingdata.com](https://flowingdata.com/2009/11/26/fox-news-makes-the-best-pie-chart-ever/)\n\n¿Qué? (╯°□°)╯︵ ┻━┻\n\n![](../images/fake_data_visualizations_2.png)\n\n\\* Imagen tomada de [flowingdata.com](https://flowingdata.com/2010/05/14/wait-something-isnt-right-here/)\n\nParen!!!! (╯°□°)╯︵ ┻━┻\n\n![](../images/fake_data_visualization_3.png)\n\n\\* Imagen tomada de [flowingdata.com](https://flowingdata.com/2012/11/09/incredibly-divided-nation-in-a-map/)\n\n![](../images/pointer.png) Moraleja: Pon atención a tus visualizaciones son TAN IMPORTANTES como los modelos que realizas, es tu responsabilidad presentar información precisa, sin sesgo y que permita a los demás tomar decisiones basadas en ellas.\n\nComo **NO** hacer una gráfica de barras \n\n![](../images/wrong_data_visualizations_1.png)\n\n\\* Imagen tomada de [viz.wtf](http://viz.wtf/)\n\n\nNo hagan esto!!!!  (╯°□°)╯︵ ┻━┻   $\\rightarrow$ Por eso en esta clase están prohibidos los pie!!!\n\n![](../images/wrong_data_visualization_2.png)\n\n\n\\* Imagen tomada de [viz.wtf](http://viz.wtf/)\n\n\n### Tipos de variables\n\n+ Datos Numéricos\n    + Numéricas continuas: métricas, ...\n    + Numéricos discretos: conteos, enteros\n+ Datos categóricos\n    + Categóricas nominales\n    + Categóricas ordinales -aunque muchas veces pueden ser tomados como numéricos-\n+ Texto, audio, imágenes\n\n### EDA no gráfico\n\n#### Univariado\n\n##### Datos categóricos\n\n¿Qué podemos encontrar? \n\n+ Valores faltantes\n+ Proporciones\n+ Frecuencias\n\n$\\rightarrow$ Generar una tabla de frecuencias de cada categoría. Por ejemplo:\n\n```{r echo=F, warning=F, message=F, error=F}\ndf <- data.frame(category=c(\"girls\",\"boys\",\"women\",\"man\",\"total\"),\n                 count=c(2,4,3,6,15),\n                 proportion=c(2/15,4/15,3/15,6/15, sum(2/15,4/15,3/15,6/15)))\n                 \n\nkable(df)\n```\n\n\n![](../images/pointer.png) Es muy importante obtener los totales para identificar errores, faltantes, anomalías en los datos\n\n##### Datos numéricos\n\nQuisieramos conocer algunas métricas de centralidad: modalidad (número de modas), mediana, media; dispersión: desviación estándar, forma -distribución teórica- para identificar si tiene colas pesadas: \\*skewness -medida de asimetría- e identificación de outliers.\n\n**Skewness:** valores cercanos a 0 indican muy poco skewness, si el número es negativo la cola es a la izquierda, si el número es positivo la cola es a la derecha \n\n![](../images/skewness.png)\n\n<br>\n\nLa mayoría de estas métricas las puedes obtener con un `summary` en R. Por ejemplo: \n\n```{r echo=T, warning=F, message=F, error=F}\ndata(mtcars)\n\nglimpse(mtcars)\nsummary(mtcars)\n```\n\n#### Multivariado\n\nEn el análisis multivariado lo que queremos encontrar son relaciones entre varias columnas -normalmente 2- \n\n##### Datos categóricos\n\n+ Cuando queremos comparar 2 variables (con pocas categorías) se puede ocupar un **cross-tabulation** donde los valores de una variable se ponen en las columans y los valores de la otra variable en renglones para armar una matriz de frecuencias.\n\nPor ejemplo: \n\n|Edad/Sexo|Mujer|Hombre|Total|\n|:---:|:---|:----:|:---:|\n|Jóven|2|3|**5**|\n|Adulto|3|5|**8**|\n|Adulto mayor|4|2|**6**|\n|**Total**|**9**|**10**|**19**|\n\n##### Datos numéricos\n\nLo más común es obtener la correlación y la covarianza entre 2 variables numéricas. Con la covarianza queremos ver qué tanto cambia una variable si la otra lo hace. \n\nEs más sencillo identificar estos cambios con la correlación, ya que esta va de [-1,1] donde -1 indica que las variables tiene una correlación lineal perfecta negativa, 1 indica que las variables tiene una correlación lineal perfecta positiva y 0 que las variables no tienen correlación. De nuevo, estas métricas son más sencillas de analizar visualmente-.\n\nCuando se tienen más de 2 variables numéricas normalmente se realizan matrices de covarianzas y correlaciones.\n\n### GEDA \n\n#### Datos Numéricos\n\n¿Qué podríamos encontrar?\n\n+ Simetría/Asimetría\n+ Huecos\n+ Outliers\n+ Multimodalidad\n+ Amontonamientos (heaping)\n+ Redondeos\n+ Imposibilidades\n+ Errores\n\n![](../images/pointer.png) ¿Cómo podríamos visualizar estas características? \n\n+ **Histograma**: Simetría/Asimetría, huecos, multimodalidad, aproximación a una distribución **empírica**\n+ **Diagrama de caja y brazos** -boxplot-: outliers, amontonamientos\n+ **Scatterplot**: Cada dato es un punto, permite identificar huecos\n* **Rugplot**: Gráfica que agrega pequeñas líneas verticales (eje x) u horizontales (eje y), se ocupa como un extra a un scatterplot, pero solo se recomienda cuando se tienen pocos datos $\\rightarrow$ veremos ejemplos de esta gráfica\n+ **Density estimate**: Como un modelo de tus datos... solo ten cuidado con los límites de las variables\n+ **Distribution estimate**: Permite comparar distribuciones como por ejemplo si una está adelante de otra\n+ **QQ-plot**: Permite comparar dos distribuciones, la tuya vs una teórica (por default la normal)\n\n\n#### Ejemplo\n\nEl siguiente histograma corresponde a las velocidades del camponato mundial de ski del 2011, ¿qué puedes decir de la gráfica?\n\n![](../images/ski_histogram.png)\n\n<br>\n\nCon el siguiente histograma ¿cambia en algo la historia/conclusión/opinión que tenías con el histograma anterior? \n\n![](../images/ski_gender_histogram.png)\n\n<br>\n\n![](../images/pointer.png) es por esto que debes hacer un análisis exploratorio profundo, ver todos los puntos de vista posibles -diferentes gráficas, diferentes análisis-\n\n#### Otro ejemplo\n\n¿Qué puedes decir de esta gráfica? \n\n![](../images/berkeley_admissions.png)\n\n<br>\n\n¿Y ahora? \n\n![](../images/berkeley_admission_gender.png)\n\n#### Otro ejemplo \n\nUtilizaremos el set de datos de precios de vivienda de Boston que viene en el paquete `MASS`, este set de datos contiene 14 variables y 506 observaciones de áreas alrededor de la ciudad de Boston. \n\n+ crim: per capita crime rate by town\n+ zn: proportion of residential land zoned for lots over 25,000 sq ft\n+ indus: proportion of non-retail business acres per town\n+ chas: Charles River dummy variable (=1 if tract  bound river; 0 otherwise)\n+ nox: nitrogen oxiides concentration (parts per 10 million)\n+ rm: average number of rooms per dwelling\n+ age: proportion of onwer-occupied units built prior to 1940\n+ dis: weighted mean of distances to fice Boston employment centres\n+ rad: index of accessibility to radial highways\n+ tax: full-value propoerty-tax rate per \\\\$10,000\n+ ptratio: pupil-teacher ratio by town\n+ black: proportion of blacks by town  ????\n+ lstat: lower status of the population (percent)\n+ medv: median value of owner-occupied homes in \\\\$1000\n\n```{r echo=F, warning=F, message=F, error=F}\nlibrary(MASS)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(readODS)\n\ndata(\"Boston\")\n\nhead(Boston)\n```\n\nEn particular nos interesa revisar la varaible **medv** \n\n+ Empecemos sin visualización, generemos una tabla con los diferentes valores de *medv* para ver qué información podemos encontrar\n\n```{r echo=T, warning=F, message=F, error=F}\ntable(Boston$medv)\n```\n\nEspero que no pienses diferente... pero tratar de sacar información de esta tabla esta difícil, solo podemos ver rápidamente que todos los números están redondeados a 1 decimal, fuera de eso... está complicado. Mejor visualizemos...\n\n```{r echo=T}\nggplot(Boston, aes(x=medv)) + \n  geom_histogram() + \n  theme_bw() + \n  ggtitle(\"Valor medio de las casas (en miles de dólares\")\n```\n\n![](../images/pointer.png) Además del warning que regresa R al generar el histograma ¿qué información puedes extraer?\n\n+ ¿Qué habrá pasado cuándo el valor *medv* anda en 25? Se ve una caída interesante\n+ El valor de *medv* parece inusual ...\n\n¿Qué pasa si cambiamos el tamaño de los bines? \n\n```{r echo=T, warning=F, error=F, message=F}\nggplot(Boston, aes(x=medv)) + \n  geom_histogram(binwidth=1) + \n  theme_bw() + \n  ggtitle(\"Valor medio de las casas (en miles de dólares\")\n```\n\nHay detalles que antes no se percibían, como que en 34 hay una caída que no se había identificado antes\n\nAhora veamos todas las variables:\n\n```{r echo=T}\nB2 <- gather(Boston, bos_vars, bos_values, crim:medv)\nggplot(B2, aes(bos_values)) +\n    geom_histogram() + \n    theme_bw() + \n    facet_wrap(~ bos_vars , scales = \"free\")\n```\n\nEste es un buen punto de partida, pero el tamaño de los bines no beneficia a todas las variables, cada variable debe tener su tamaño de bin adecuado, por otro lado la escala varía mucho entre variables: hay unas que van de 0 a 20 y otras de 0 a 400.\n\n#### Ejercicio\n\n1. Utiliza la variable *medv* para generar las siguientes gráficas en R: ¿Qué observas en cada una de estas gráficas?\n\n+ `?boxplot`\n+ `?stripchart` Un scatterplot de 1 dimensión, puede ser una alternativa al boxplot cuando tienes **pocos** datos\n+ `?stem`\n+ `?density` Necesitarás agregar un plot para ver la gráfica\n+ `?rug` Primero necesitarás generar o el stripchart o el density para agregarle rug\n\n\n\n```{r echo=T, warning=F, message=F, error=F}\n#boxplot\nggplot(Boston, aes(x=\"var\", y=medv)) +\n  geom_boxplot() +\n  theme_bw() + \n  coord_flip() +\n  ggtitle(\"boxplot variable medv\")\n\n#stripchart\nstripchart(Boston$medv)\n\n#stem\nstem(Boston$medv)\n\n#density\nplot(density(Boston$medv))\n\n#rug\nrug(Boston$medv)\n```\n\n2. En la gráfica de las 14 variables mostrada arriba ¿Cómo describirías las distribuciones? ¿Para cuales variables sería mejor utilizar boxplot? ¿Por qué?\n\n```{r echo=T, warning=F, error=F, message=F}\nggplot(Boston, aes(x=\"var\", y=black)) +\n  geom_boxplot() +\n  theme_bw() +\n  coord_flip() + \n  ggtitle(\"Boxplot variable black\")\n\nggplot(Boston, aes(x=\"var\", y=crim)) +\n  geom_boxplot() +\n  theme_bw() +\n  coord_flip() + \n  ggtitle(\"Boxplot variable crim\")\n\nggplot(Boston, aes(x=\"var\", y=tax)) +\n  geom_boxplot() +\n  theme_bw() +\n  coord_flip() + \n  ggtitle(\"Boxplot variable tax\")\n\nggplot(Boston, aes(x=\"var\", y=zn)) +\n  geom_boxplot() +\n  theme_bw() +\n  coord_flip() + \n  ggtitle(\"Boxplot variable zn\")\n```\n\n#### Otro ejemplo \n\nVeamos ahora un poco de outliers con un dataset de películas que viene en el paquete `ggplot2movies` -antes formaba parte del paquete ggplot pero se hizo su propio paquete para bajar el overhead de bajar ggplot2- \n\n```{r echo=T, warning=T, error=F, message=F}\nlibrary(ggplot2movies)\nlibrary(dplyr)\nlibrary(scales)\nlibrary(plotly)\n\ndata(movies)\n\nglimpse(movies) \n\n## histograma\nggplot(movies, aes(x=length)) + \n  geom_histogram() +\n  scale_y_continuous(label=comma) + \n  scale_x_continuous(label=comma) + \n  theme_bw()\n\n```\n\n¯\\\\(º_o)/¯ chanclas... no dice mucho la gráfica... ¿o si? y además, ¿por qué sale más de 4,000 en longitud de la película? veamos qué hay ahí\n\n```{r echo=T, warning=F, error=F, message=F}\nmovies %>% \nfilter(length > 2000) %>% \narrange(desc(length))\n```\n\nPara encontrar estos *outliers* es más sencillo hacer diagramas de caja y brazos\n\n```{r echo=T, warning=F, error=F, message=F}\np <-ggplot(movies, aes(x=\"var\", y=length)) +\n  geom_boxplot() +\n  scale_x_discrete(breaks=NULL) +\n  scale_y_continuous(label=comma) +\n  theme_bw() + \n  coord_flip()\n\np \n\n#o con plotly para saber los numeros :P\nggplotly(p)\n```\n\nPuedes obtener los outilers (valores) con la función boxplot \n\n```{r echo=T, warning=F, error=F, message=F}\noutliers_info <- boxplot(movies$length)\nsummary(outliers_info) # las cosas que te devuelve el outlier \n\n# cuantos \nformat(outliers_info$out %>% length(), big.mark=\",\")\n```\n\nVeamos cómo se ve el histograma si quitamos estos valores atípicos\n\n```{r echo=T, warning=F, error=F, message=F}\nggplot(movies, aes(x=length)) + \n    xlim(0, 180) +\n    geom_histogram(binwidth = 1) +\n    xlab(\"Duración de películas en minutos\") + \n    theme_bw()\n```\n\nque diferencia!\n\n![](../images/pointer.png) **Ejercicio 1/Tarea 3** A entregar el **lunes 9 de octubre 2017** en tu carpeta dentro de carpeta `alumno` con el nombre ejercicio_eda_1 (entregar Rmd y html) \n\na. ¿Qué puedes decir de esta gráfica?\nb. ¿Cómo la modificas para agregar más ticks?\nc. Haz una gráfica que muestre que los picos de 7 y 90 minutos existían antes y después de 1980\nd. Existe la varaible `short` que indica si una película es \"corta\", ¿Qué gráfica puedes hacer para identificar el criterio que se ocupó para definir esta variable y cuáles están mal clasificadas? \n\n*** \n\n#### Datos categóricos\n\n¿Qué podemos encontrar?\n\n+ Patrones insesperados en los resultados\n+ Malas Distribuciones\n+ Categorías extras\n+ Experimentos no balanceados\n+ Muchas categorías\n+ \"No sé\", Errores, Faltantes\n\n![](../images/pointer.png) ¿Cómo podríamos visualizar estas características? \n\n+ **Barchars:** Nominales, Variables discretas\n+ Explora (o ten cuidado con) diferentes ordenamientos\n+ Es posible que datos ordinales entren también en este análisis\n\n#### Bivariado contínuo\n\n¿Qué podemos encontrar?\n\n+ Relaciones lineales y no lineales\n+ Asociaciones\n+ Outliers: Se puede ser outlier en una dimensión y no serlo en dos, o viceversa\n+ Clusters\n+ Huecos\n+ Barreras\n+ Relación condicional\n\nModelos y pruebas\n\n+ Correlación\n+ Smoothing\n+ Regresión lineal $\\rightarrow$ Verifica los supuestos!!!! \n\n¿Regresión lineal? ... residuales \n\n![](../images/oreally.png)\n\n\n#### Ejemplos\n\nAhora veamos la varaible `rating` que representa el promedio de calificaciones de IMDB y la variable `votes` que representa el número de personas que calificaron la película\n\n```{r echo=T, warning=F, message=F, error=F}\nggplot(movies, aes(x=votes, y=rating)) +\n  geom_point() +\n  ylim(1,10) + \n  scale_x_continuous(label=comma) + \n  theme_bw()\n```\n\n![](../images/pointer.png) **Ejercicio 2/Tarea 3** A entregar el **lunes 9 de octubre 2017** en tu carpeta dentro de carpeta `alumno` en el mismo archivo creado en el ejercicio 1\n\na. Agrega `alpha-blending` ¿Qué pasa con los outliers? ¿Diferentes valores funcionan mejor?\nb. ¿Cómo se ve la gráfica si remueves las películas con menos de 100 votos?\nc. ¿Cómo se ve la gráfica si remueves todas las películas que tienen un rating arriba de 9?\n\n***\n\nEs posible estudiar posibles modelos (al igual que en el caso univariado) por ejemplo, ocupando el set de datos `Cars93` en el paquete MASS:\n\n```{r echo=T, warning=F, message=F, error=F}\ndata(\"Cars93\")\n\nggplot(Cars93, aes(x=Weight, y=MPG.city)) +\n  geom_smooth(colour=\"green\") +\n  ylim(0, 50) + \n  scale_x_continuous(label=comma) +\n  geom_point() +\n  theme_bw() \n```\n\n![](../images/pointer.png) **Ejercicio 3/Tarea 3** \n\na. ¿Cuál es el outlier de la izquierda?\nb. En muchos países en lugar de medirse en millas por galón, se mide en litros por 100 km. ¿Qué pasa si graficas `MPG.city` contra `Horsepower`? ¿Existe una relación lineal? ¿Cuáles son los outliers?\n\n*** \n\nTambién se podemos hacer una matriz de scatterplots -**splom** (como lo hicimos con los histogramas :)), para ello ocupamos el método `ggpairs` de la librería `GGally` en el dataset de precios de vivienda ade Boston.\n\n```{r echo=T, message=F, error=F, warning=F}\nlibrary(GGally)\n\n\ndplyr::select(Boston, -rad, -chas) %>% \nggpairs(title=\"Boston dataset\", diag=list(continuous=\"density\", axisLabels='none'))\n  \n```\n\n![](../images/pointer.png) **Ejercicio 4/Tarea 3** \n\na. ¿Cuáles están positivamente correlacionados con `medv`?\nb. La variable `crim` -tasa de crímenes per cápita- tiene *scatterplots* con forma inusual, donde los valores altos de `crim` solo ocurren para un valor de la otra variable ¿Qué explicación le puedes dar?\nc. Hay varias formas en los *scatterplots*, escoge 5 y explica cómo las interpretas\n\n*** \n\n#### Más de 2 variables continuas\n\nPara ver variables variables continuas se puede ocupar el *parallel coordinate plot* **pcp**, estos diagramas permiten dar un vista rápida a las distribuciones univariadas de varias variables a la vez: si son skew, si hay outliers, si hay gaps, etc. \n\nAhora utilizaremos el dataset `iris` para probar estas gráficas utilziando de la librería `GGally` el método `ggparcoord`\n\n```{r echo=T, warning=F, error=F, message=F}\ndata(iris)\n\nggparcoord(iris, columns=1:4, groupColumn = \"Species\") \n```\n\nEsta está más difícil de interpretar... \n\nEn un **pcp** cada línea es una observación del dataset, y cada atributo/variable del set es un punto en la gráfica. \n\nLo que uno observa en la gráfica depende del orden en el cuál se dibujan los ejes. Hay autores que sugieren intentar varias combinaciones o inclusive poner varias copias de los ejes. Quizá lo mejor sea tener una gráfica interactiva para tal efecto... lo veremos más adelante. \n\nEste tipo de gráficas se puede usar para comparar modelos, series de tiempo, análisis de clusters, índices, etc. Esto lo discutiremos más adelante en el curso. Lo que se busca al ocupar esta gráfica es encontrar **similitudes** al comparar diferentes características del dataset.\n\nHay varias cosas que ajustar en estas gráficas para poder ser interpretadas: el orden de las variables y el escalamiento de los datos. \n\n+ **Escalamiento:** Cuando vamos a comparar diferenes mediciones tenemos que determinar alguna manera de ponerlos en la misma escala. En las gráficas **pcp** por default, la escala depende del máximo y mínimo valor encontrado por cada variable, el mínimo a $0$ y el máximo se maperará a $1$ (o 0% y 100%) \n\n$$y_{ij}=\\frac{x_{ij} - \\min_i x_{ij}}{\\max_i x_{ij} - \\min_i x_{ij}}$$\n\nOtra forma de escalar los datos es usando la desviación estándar o el rango intercuantil (IQR), por ejemplo: \n\n$$z_{ij}=\\frac{x_{ij} - \\bar{x}_j}{sd(x_j)}$$\n\nEste es el escalamiento por default que ocupa `ggparcoord`.\n\n![](../images/pointer.png) La escala de cada variable es propia a esa variable, es decir, no se deben comparar las alturas entre diferentes variables (diferentes puntos en el eje x)\n\n```{r echo=T, warning=F, message=F, error=F}\niris1 <- iris\nnames(iris1) <- c(abbreviate(names(iris)[1:4]), \"Species\")\na1 <- ggparcoord(iris1, columns = 1:4, \n                 alphaLines = 0.7,  \n                 groupColumn = \"Species\") + \n  ggtitle(\"a1\")\na2 <- ggparcoord(iris1, columns = 1:4, \n                 scale=\"uniminmax\", \n                 alphaLines=0.7, \n                 groupColumn = \"Species\") + \n  ggtitle(\"a2\")\na3 <- ggparcoord(iris1, columns = 1:4, \n                 scale=\"globalminmax\", \n                 alphaLines=0.7, \n                 groupColumn = \"Species\") + \n  ggtitle(\"a3\")\na4 <- ggparcoord(iris1, columns = 1:4, \n                 scale=\"center\", \n                 scaleSummary=\"median\", \n                 alphaLines=0.7, \n                 groupColumn = \"Species\") +\n  ggtitle(\"a4\")\n\ngridExtra::grid.arrange(a1, a2, a3, a4)\n```\n\n![](../images/pointer.png) **Ejercicio 5/Tarea 3** \n\na. Usando el dataset `Boston` realiza un *pcp*, intenta resaltar las características que haz observado en los ejercicios anteriores. Piensa cómo le hiciste...\n\n*** \n\n#### Varias variables categóricas\n\nCuando queremos comparar varias variables categóricas al mismo tiempo tenemos el problema de que haya muchas categorías por variable y la gran cantidad de posibles ordenamientoso de las variables. Por ejemplo, para $J$ variables categóricas con $c$ número de categorías, las variables pueden ser ordenadas de $J!$ maneras diferentes y las categorías dentro de las variables de $\\Pi_{j=1}^J c_j!$, lo cual da un total de $J!\\Pi_{j=1}^Jc_j!$ ordenamientos, o sea un montón...\n\nLos tipos de gráficas que podemos ocupar en estas situaciones son: \n\n+ *mosaicplots*\n+ *doubledecker plots*\n+ *fluctuation diagrams*\n+ *treemaps*\n+ *association plots*\n+ *parallel sets/categorical parallel coordinate plots*\n\n![](../images/pointer.png) [New approaches in Visualization of Categorical Data: R Package extracat de A. Pilhöfer y A. Unwin. JSS, Vol53 issue 7, May 2013.](https://www.jstatsoft.org/article/view/v053i07/v53i07.pdf)\n\n##### Doubledecker \n\nEn esta gráfica las variables se dividen en variables explicativas y variable objetivo, esta última ocupa el eje vertical \n\n```{r echo=T, warning=F, message=F, error=F}\nlibrary(vcd)\n\ndata(Titanic)\n\n#variables a ocupar para hacer una tabla de contingencia, la variable tardet se pone al final\ndoubledecker(Survived ~ Sex, data=Titanic, gp=gpar(fill=c(\"grey90\", \"darkblue\")))\n\ndoubledecker(Survived ~ Class, data=Titanic, gp=gpar(fill=c(\"grey90\", \"darkblue\")))\n```\n\n<br>\n\nConforme más variables agregamos se vuelve más difícil la interpretación: \n\n```{r echo=T, warning=F, message=F, error=F}\ndoubledecker(Survived ~ Sex + Class, data=Titanic, gp=gpar(fill=c(\"grey90\", \"darkblue\")))\n```\n\n<br>\n\nAdemás, como mencionábamos, al ser una tabla de tipo *mosaic* la construcción de la gráfica depende del orden de las variables\n\n```{r echo=T, warning=F, message=F, error=F}\ndoubledecker(Survived ~ Class + Sex, data=Titanic, gp=gpar(fill=c(\"grey90\", \"darkblue\")))\n```\n\n<br>\n\n##### Mosaicplot\n\nEn este tipo de gráfica ocupamos rectángulos proporcionales a los conteos de las combinaciones que los rectángulos representan. Se dibujan partiendo con un rectángulo que representa todo el *dataset*, luego se toma la primer variable y se parte el eje horizontal en secciones proporcionales a los tamaños de las categorías.\n\n```{r echo=T, warning=F, message=F, error=F}\ntitanic <- as.data.frame(Titanic)\npar(mfrow=c(2,2),  mar= c(4, 4, 0.1, 0.1))\nmosaicplot(xtabs(Freq ~ Survived, data=titanic), main=\"\")\nmosaicplot(xtabs(Freq ~ Survived + Sex, data=titanic), main=\"\")\nmosaicplot(xtabs(Freq ~ Survived + Sex + Class, data=titanic), main=\"\")\nmosaicplot(xtabs(Freq ~ Survived + Sex + Class + Age, data=titanic), main=\"\")\n```\n\nDe nuevo el orden de las variables determinará la apariencia (y tal vez el *insight* que puedes obtener)\n\nOtra opción es utilizar `pairs`\n\n```{r echo=T, warning=F, message=F, error=F}\npairs(xtabs(Freq ~ ., data=titanic))\n```\n\nLa diagonal de esta gráfica contiene gráficas de barra para las variables individuales y *mosaicplots* en los elementos que no están en la diagonal. Si hay muchas variables esta gráfica será muy difícil de leer.\n\nSi existe una variable a explicar obvia (en nuestro caso Survived), quizá sea mejor tomar esto en cuenta en nuestro análisis:\n\n```{r echo=T, warning=F, message=F, error=F}\nggplot(titanic, aes(Survived, Freq, fill=Sex)) + \n    geom_bar(stat = \"identity\") +\n    theme_bw() +\n    facet_grid(Class ~ Sex + Age) + theme(legend.position=\"none\")\n```\n\n\n##### Fluctuation diagrams\n\nSi queremos observar tablas de contingencia muy grandes o matrices de confusión, podemos usar las gráficas de tipo *fluctile*. En particular estas gráficas resaltan qué subgrupos aparecen más frecuentemente, o cuales combinaciones no aparecen en lo absoluto.\n\n```{r echo=T, warning=F, error=F, message=F}\nlibrary(extracat)\n\n#nota que requiere una tabla de entrada! no un data frame\nfluctile(Titanic)\n```\n\nPor otro lado, si solo nos interesa comparar las tasas, podemos usar la funcion `rmb` -*relative multiple barchar*- con el parámetro `freq.trans=\"const\"`:\n\n```{r echo=T, warning=F, message=F, error=F}\nrmb(formula = ~ Sex + Class + Age + Survived, \n              data=titanic, \n              cat.ord=2, spine=TRUE, freq.trans=\"const\")\n```\n\nEn esta gráfica vemos las tasas de supervivencia (el color verde) por subgrupo. Esto sería muy difícil de apreciar con un *mosaicplot* normal.\n\nLas **rmb** mezclan las gráficas de barras y los *mosaicplots*.\n\n\n\n### Forma deseable de los datos\n\nPara muchos de los análisis de datos requerimos que los datos estén en formato *tidy*\n\n+ ![](../images/pointer.png) [Artículo Tidy Hadley Wickham](http://vita.had.co.nz/papers/tidy-data.pdf)\n+ También habrá ejemplos en los que no queremos que esté en formato *tidy* [Non Tidy Data](https://simplystatistics.org/2016/02/17/non-tidy-data/) + O grafos! (lo veremos más adelante)\n\n![Tidy Data](http://r4ds.had.co.nz/images/tidy-1.png)\n\n*Fuente: R for Data Science, Wickham and Grolemund, 2016*\n\nEs decir:\n\n1. Cada *variable* una columna\n2. Cada *observación* un renglón\n3. Cada *valor* una celda\n\n![](../images/data_analysis_and_cleaning.png)\n\n*Fuente: [Presentaciones de Hadley Wickham](http://vita.had.co.nz/papers/tidy-data-pres.pdf)*\n\n#### Formatos salvajes\n\nLos siguientes ejemplos de dataset son típicos de algunas fuentes de datos, por ejemplo: INEGI (al menos en formatos al 2014)\n\n||Lat|Long|Indicador|\n|:----:|:------:|:-------:|:--------:|\n|Obs1| \\# | \\# | \\# | \n\n\nTable: Fecha implícita\n\n| | lugar | indicador |\n|:---:|:-----:|:-----:|\n|obs 1 |  | |\n|obs 2 | |  |\n\n\nTable: Otro con Fecha implícita \n\n| |Fecha 1 | Fecha 2 |\n|:---:|:-----:|:------:|\n|lugar 1|    |   |\n|lugar 2|  | |\n\nTable: Implícita la variable, ¿¿por qué?? (╯°□°)╯︵ ┻━┻\n\n|  |  Fecha 1 | Fecha 2 | ... |\n|:-----:|:-------:|:-------:|:------:|\n| **LUGAR 1** |   |    |   |  |\n| Ind 1 |   #  | #   | ... |\n| Ind 2 |   #  |  #   | ... |\n| **LUGAR 2** |   |    |   |  |\n| Ind 1 |   #  | #   | ... |\n| Ind 2 |   #  |  #   | ... |\n\nO cosas más locas! \n\n||Indicador 1|Indicador 2|\n|:--:|:--:|:---:|\n\n||Fecha 1| Fecha 2| Fecha 1| Fecha 2|\n|:-----:|:--:|:-------:|:-----:|:-----:|\n|lugar 1| Ind 1| Ind 1 | Ind 2| Ind 2|\n|lugar 1| Ind 1| Ind 1 | Ind 2| Ind 2|\n\nOtro ejemplos: \n\n+ Nombres de las columnas representan valores de los datos en lugar de nombres de variables -el nombre de un lugar por ejemplo-\n+ Una columna contiene varias variables en lugar de una variable \n+ Una tabla contiene más de una unidad de observación\n+ Las variables están contenidas en los renglones y columnas, en lugar de sólo columnas.\n+ Los datos de una unidad observacional están dispersas en varios *data sets*\n\nEjemplos:\n\n```{r echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}\nlibrary(tidyr)\n\nmessy <- data.frame(nombre=c(\"juan.perez.lopez\",\"martha.lopez.benitez\",\n                             \"jesus.ramirez.perez\",\"jose.martinez.lopez\",\n                             \"aurora.saldivar.salazar\"),\n                    genero_edad=c(\"m.35\",\"f.23\",\"m.30\",\"m.25\",\"f.33\"),\n                    time=c(1,3,4,5,6))\n\nmessy\n```\n\nTendríamos que dejarlo *tidy*:\n\n+ Separando el nombre\n```{r echo=T, warning=F, error=F, message=F}\nsemi_messy <- messy %>% separate(col=nombre, into=c(\"nombre\",\n                                      \"apellido_paterno\",\n                                      \"apellido_materno\"), \n                   sep=\"\\\\.\")\n\nsemi_messy\n```\n\n+ Separando género y edad\n\n\n```{r echo=T, warning=F, error=F, message=F}\nclean <- semi_messy %>% separate(col=genero_edad, into=c(\"genero\",\"edad\"), \n                   sep=\"\\\\.\")\n\nclean\n```\n\nOtro ejemplo: ¿Qué está mal?\n\n```{r echo=T, warning=F, error=F, message=F}\nmessy <- data.frame(pais=c(rep(\"Afganistan\",4),\n                           rep(\"Brazil\",4),\n                           rep(\"China\",4)),\n                    year=c(rep(1999,2),rep(2000,2),\n                           rep(1999,2),rep(2000,2),\n                           rep(1999,2),rep(2000,2)),\n                    llave=c(\"casos\",\"poblacion\",\"casos\",\"poblacion\",\n                          \"casos\",\"poblacion\",\"casos\",\"poblacion\",\n                          \"casos\",\"poblacion\",\"casos\",\"poblacion\"),\n                    valor=c(75,1300000,134,1400000,\n                            10000,100000000,12000,120000000,\n                            56000,150000000,60000,170000000))\n\nmessy\n```\n\nLo deberíamos arreglar con: \n\n```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}\nclean <- messy %>% spread(key=llave, value=valor, fill=NA)\n\nclean\n```\n\nEl último\n\n```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}\nstocks <- data_frame(\n  time = as.Date('2009-01-01') + 0:9,\n  X = rnorm(10, 0, 1),\n  Y = rnorm(10, 0, 2),\n  Z = rnorm(10, 0, 4)\n)\n\nstocks\n\nstocks %>% gather(stock, price, -time)\n```\n\n### Casos de estudio\n\n#### Reproducibilidad\n\nEn estos casos de estudio nos vamos a encontrar con nuestro primer tipo de *pipeline*, en este caso en particular, este *pipeline* no es para ejecutar grandes volúmenes de datos o para ejecutar contínuamente, sino para poder reproducir el proceso de exploración y modelado de datos.\n\n![](../images/pointer.png) Antes de empezar te recomiendo ampliamente que utilices `packrat` para la administración de paquetes en R [packrat](https://rstudio.github.io/packrat/)\n\nEn tu carpeta crea las carpetas `german` y `algas` dentro de ellas crea los archivos: \n\n+ 00-load.R\n+ 01-prepare.R\n+ 02-clean.R\n+ run.R\n\nEn estos archivos pondrás código para ejecutar los pipelines de los siguientes casos de estudio\n\n### German\n\n#### **¿Quién eres?**\n\nEres el científico de datos de un banco alemán, el banco tiene muchas pérdidas debido a malos créditos y quiere reducirlas. \nTe piden realizar esta tarea, indicando que quieren reducir la tasa de pérdidas en un 10%.\n\nNeceistaras lo siguiente:\n\n```{r eval=F}\nrm(list = ls())\n\ninstalar <- function(paquete) {\n\n    if (!require(paquete,character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)) {\n        install.packages(as.character(paquete), dependecies = TRUE, repos = \"http://cran.us.r-project.org\")\n        library(paquete, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)\n    }\n}\n\npaquetes <- c('lubridate', 'magrittr', 'ggvis', 'dplyr', 'tidyr', 'readr', 'rvest', \n              'ggplot2', 'stringr', 'ggthemes', 'googleVis', 'shiny', 'tibble', 'vcd', 'vcdExtra',\n              'GGally', 'readODS', 'readxl', \"RSQLite\")\n\nlapply(paquetes, instalar);\n\nsource(\"metadata.R\")\nsource(\"utils.R\")\n```\n\n\n#### **Datos**  \n\nUsaremos para este ejemplo, los datos de crédito alemán (*German data set*). \n[German Credit Data](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29)\n\n#### **Carga de datos**\n\n```{r echo=F, warning=F, message=F, error=F}\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggthemes)\n```\n\n```{r echo=T, warning=F, message=F, error=F}\ngerman_url <- paste0('http://archive.ics.uci.edu/ml',\n                    '/machine-learning-databases/statlog',\n                    '/german/german.data')\ngerman_data <- read_delim(german_url, \n                          col_names=F,\n                          delim=\" \")\n```\n\nTenemos `r format(dim(german_data)[1], big.mark=\",\")` observaciones y  `r format(dim(german_data)[2], big.mark=\",\")` variables. Veamos cómo están los datos: \n\n```{r echo=T, warning=F, message=F, error=F}\nhead(german_data)\n```\n\n¿Qué? (╯°□°)╯︵ ┻━┻\n\n**Ejercicio** \n\n+ Crea una función `load` en `utils.R` en tu carpeta que descargue **si y solo si** no existe un archivo `german.rds`, si no existe descarga y guarda el archivo. \n+ `?saveRDS`, `?readRDS`, `?file.exists`\n\n#### **Transformación de datos**\n\nLos nombres de las columnas fueron copiados a mano desde [`german.doc`](https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc), los nombres se encuentran en el archivo `metadata.R`\n\n```{r echo=T, warning=F, message=F, error=F}\nsource(\"utils.R\")\n\ngerman_colnames\n```\n\nLa variable de salida la definimos como categórica (`factor` en `R`)\n```{r echo=T, warning=F, message=F, error=F}\ncolnames(german_data) <- german_colnames\n\ngerman_data$good_loan <- as.factor(\n                          ifelse(\n                            german_data$good_loan == 1, \n                            'GoodLoan', \n                            'BadLoan'\n                            )\n                          )\n```\n\n#### **Decodificar**\n\n- Crea una función `german_decode` en un archivo `utils.R` dentro de tu carpeta, \nesta función debe de utilizar `german_codes` (en el archivo `metadata.R`) para   \ndecodificar los elementos  de todas las columnas (por ejemplo `A201` -> `yes`)\n\n- Utiliza `dplyr` para decodificar todas las columnas de `german_data`\n\n![](../images/pointer.png) TIP: verifica el uso de `left_join`, `rbind` y `cbind`\n\n```{r echo=T, warning=F, message=F, error=F}\ngerman_data  <- german_data %>% \n                     mutate_all(funs(german_decode))\n\ngerman_data\n```\n\n#### **Datos manejables**\n\nEn este momento deberás de tener archivos `00-load.R`, `01-prepare.R`, `02-clean.R`,  `metadata.R` \ny un archivo `utils.R` dentro de `german`.  \nAdemás deberías de tener un archivo `german.rds`.\n\n**Ejercicio**\n\n- ¿Hay algo raro con los datos de préstamo?\n\n- ¿Cuál crees que debería ser la distribución del resultado del \n  préstamo `Good_Loan` respecto a `Credit history`?\n\n- Grafícalo y comenta tus resultados.\n\n- Si lo vas a hacer con `ggplot2` usa este \n[cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/12/ggplot2-cheatsheet-2.0.pdf) \no estos [ejemplos](http://docs.ggplot2.org/current/)\n\n<div style=\"background-color:#ffcf40\">\n\n**Tarea 4** Entrega **lunes 16 de octubre 23:59:59 CST** en tu carpeta `alumnos/german`\n\n+ Dentro de tu carpeta german tu archivo `utils.R`, `00-load.R`, `01-prepare.R`, `02-clean.R` y `run.R`. $\\rightarrow$ Si tuvo sentido para ti poner las funciones en util y nada más ... entonces solo sube tu `util.R` -te recomiendo que aunque hayas creado las funciones ahí de todas maneras generes el archivo 00 y 01 por claridad y sanidad mental tanto tuya como la de tu equipo :)- \n+ Tener la función load completa: bajar el *dataset* `german` si no existe y guardárla como rds, o si ya existe, cargarla con readRDS\n+ Tener la función de german_decode: si prefieres ocupar tu propia implementación adelante -de hecho es preferible- cada quién resuelve un problema a su manera y es mejor que te quede bastante claro como solucionar este problema porque te enfrentarás a él MUCHAS veces\n+ ¿Encontraste algo raro en los préstamos? ¿Qué? ¿Cómo lo encontraste?\n+ ¿Cuál crees que debería ser la distribución del resultado del \n  préstamo `Good_Loan` respecto a `Credit history`? Grafícalo y comenta tus resultados $\\rightarrow$ checa los tips de como gráficarlo con ggplot2 -te van a salir cosas *raras=feas (visualmente)*- pero no te estreses, las arreglaremos la siguiente clase ╭(◔ ◡ ◔)/\n\n</div>\n\n![](../images/reproducibility_pipeline_a.png)\n\n![](../images/reproducibility_pipeline_b.png)\n\n**Ejercicio**\n\n- Fue terrible poder hacer la gráfica con `ggplot2` utilizando los nombres de\ncolumnas que pusimos (`german_colnames`).\n\n- Modifica el archivo donde tengas `german_colnames` (puede ser `utils.R` o `metadata.R`) y \nsustituye (usando quizá `stringr` o `grep`) los `' '` y `'/'` por `'_'` (ve la [guía de \nestilo](http://adv-r.had.co.nz/Style.html)) y pasa todo a minúsculas.\n\n- Ejecuta todo de nuevo (¡la ventaja de ser reproducible!)\n\n```{r echo=T, warning=F, message=F, error=F}\ncolnames(german_data) <- german_clean_colnames(german_colnames)\n\ncolnames(german_data)\n```\n\n#### **Intermedio**\n\n+ Si la gráfica de barras te quedó desacomodada, este código ordena los `bar charts` (Adolfo de Unánue)\n\n```{r echo=T, warning=F, message=F, error=F, fig.width=13}\ngerman_data %>% \n    group_by(credit_history) %>% \n    dplyr::summarise(count = n()) %>% \n    arrange(desc(count)) %>% \n    ggplot(.) + \n        geom_bar(aes(x=reorder(credit_history, count), y = count), stat=\"identity\", fill=\"gray\") + \n        coord_flip() + \n        theme_hc() + \n        ylab('casos') + \n        xlab('Historial de crédito')\n```\n\nYo me lo sé pasando a factores los nombres y ordenándo los niveles como necesites presentarlos -salida de una `arrange`-\n\n```{r echo=T, warning=F, message=F, error=F}\nplot_sorted <- german_data %>% group_by(credit_history) %>%\n  summarise(count=n()) %>%\n  arrange(count) #como haremos coord flip necesitamos ordenarlas de manera inversa a como queremos que aparezcan en el coord_flip\n\nplot_sorted$credit_history <- factor(plot_sorted$credit_history,\n                                     levels=plot_sorted$credit_history)\n\nggplot(plot_sorted, aes(x=credit_history, y=count), fill=\"gray\") +\n  geom_bar(stat=\"identity\") +\n  coord_flip() +\n  theme_hc() +\n  ylab(\"casos\") +\n  xlab(\"Historial de crédito\")\n```\n\n\n#### **Sanidad de los datos**\n\n+ El nombre de la columna no significa lo que tu crees que significa\n\n+ El significado de la columna cambia con el paso del tiempo o la metodología para medir esa variable.\n\n+ Mucha / muy poca resolución\n\n+ Los valores `missing` no son realmente faltantes (`NAs`), si no que significan algo\n    + Regularmente no documentado\n    \n+ Si es un `csv` de seguro a alguien ya le pareció chistoso ponerle comas dentro de los valores de las columnas \n    + Existe una historia parecida para los `tsv`, `psv`, etc.\n\n#### `summary`\n\nUn uso del  `summary()` es detectar problemas en los datos.\n\n- ¿Valores faltantes?\n    - ¿Hay una variable con muchos faltantes? ¿Por qué? ¿Es un error? ¿Significa algo?\n    \n- ¿Valores inválidos?\n    - ¿Hay negativos donde no debería de haber? (Como en edad, ingreso, estatura)\n    - ¿Texto en lugar de números?\n\n\n- ¿Outliers?\n    - Son aquellos valores que no crees que deberían de estar (En el ejemplo de edad 1400 años)\n\n- ¿Rangos?\n    - Es importante saber cuanto varía la variable.\n    - Si es muy amplio, puede ser un problema para algunos algoritmos de modelado.\n    - Si varía muy poco (o nada) no puede ser usado como predictor.\n    \n- ¿Unidades?\n    - ¿El salario es mensual?¿Quincenal?¿Por hora?\n    - ¿Los intervalos de tiempo están en segundos?¿Años?\n    - ¿Las longitudes? ¿La moneda?\n\n\n**Ejercicio**\n\nRevisa `german_data` con `summary()`, reporta alguna anomalía.\n\n\n```{r echo=T, warning=F, message=F, error=F}\nsummary(german_data)\n```\n\n**Ejercicio**\n\nAsegurar que el *dataset* esté en forma *tidy*, si no lo está haz que esté en formato tidy (puede quedar en prepare/utils) Guarda esto en `german-tidy.rds`\n\n\n*** \n\n### Algas\n\n#### ¿Quién eres? \n\nComo el dinero no alcanza, tomas otro trabajo rápido para una ONG. Quieren predecir \nla concentración de algas en ríos de la región. Tomaron datos durante un año. \n\nCada observación es el efecto de agregar varias muestras de agua recolectadas \nen el mismo río por un periodo de 3 meses en la misma estación del año.\n\n\n#### Datos \n\nLos datos provienen de [Coil 1999 Competition \nData](https://archive.ics.uci.edu/ml/datasets/Coil+1999+Competition+Data) sobre contaminación de ríos.\nLa explicación de los datos se puede ver [aquí](https://archive.ics.uci.edu/ml/machine-learning-databases/coil-mld/coil.data.html)\n\n```{r}\nalgas_url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/coil-mld/analysis.data'\n\nalgas <- read_csv(algas_url, \n                  col_names = algas_colnames,\n                  na = 'XXXXXXX')\n```\n**Ejercicio**\n\n- Repite los pasos realizados para `german.data` con `algas`\n- Revisa con `summary()`, reporta alguna anomalía.\n\n\n```{r}\nsummary(algas)\n```\n\n¿Por qué la columna `NO3` **no** es numérica?\n\n```{r}\nproblems(algas)\n```\n\nEl problema lo podemos observar, por ejemplo, en la observación `20`\n\n```{r}\nalgas[20,]\n```\n\nOtra cosa interesante a notar, es que hay justo `r length(problems(algas))` casos de `a7` con `NA`s. \nAl parecer el error en la columna de `NO3` se está \"comiendo\" a la columna `a7`.\n\n```{r}\nalgas[problems(algas)$row,]\n```\n\nLa columna de `NO3` está capturada a 5 decimales. Parece lógica la suposición de \ndividir esa columna a los 5 decimales.\n\nPodemos limpiar esta columna haciendo lo siguiente\n\n```{r}\nproblematic_rows <- problems(algas)$row\n\nalgas[problematic_rows,] <- algas %>% \n    slice(problematic_rows) %>% \n    unite(col=\"all\", -seq(1:6), sep = \"/\", remove=TRUE) %>%\n    extract(all, into=c(\"NO3\", \"NH4\", \"resto\"),\n            regex=\"([0-9]*.[0-9]{5})([0-9]*.[0-9]*)/(.*)/NA\", remove=TRUE) %>%\n    separate(resto, into=names(algas)[9:18], sep=\"/\", remove=TRUE)    \n\nalgas[19:20,]\n```\n\n¿Qué pasó aquí? \n\n```{r eval=F}\nalgas %>%\n  slice(problematic_rows) %>% head()\n\nalgas %>% \n  slice(problematic_rows) %>%\n  unite(col=\"all\", -seq(1:6), sep=\"/\", remove=T)\n\nalgas %>% \n  slice(problematic_rows) %>%\n  unite(col=\"all\", -seq(1:6), sep=\"/\", remove=T) %>%\n  extract(all, into=c(\"NO3\", \"NH4\", \"resto\"),\n            regex=\"([0-9]*.[0-9]{5})([0-9]*.[0-9]*)/(.*)/NA\", remove=T)\n```\n\n```{r}\nalgas <- readr::type_convert(algas)\n\nalgas\n```\n\n\n```{r eval=F}\nalgas <- algas %>%\n            mutate_all(funs(algas_clean))\n\nalgas\n```\n\n\nRevisando el resumen estadístico con  `summary`:\n\n```{r}\nsummary(algas)\n```\n\nLos tipos de datos:\n\n```{r}\nglimpse(algas)\n```\n\n\n#### Usando gráficas\n\n- El resumen estadístico quizá no cuente toda la historia.\n- El siguiente paso es explorar mediante gráficas.\n- Es un proceso iterativo.\n\n##### Una sola variable \n\n- ¿Cuál es el pico? ¿Coincide con la media? ¿La mediana? ¿Existe?\n- ¿Cuántos picos?\n  - Si es `bimodal` o `multimodal` quizá haya varias poblaciones en lugar de una y será mejor modelar por separado.\n- ¿Qué tan normal es? ¿El log-normal? \n    - Utiliza una gráfica `Q-Q`\n- ¿Cuánto varía? ¿Está concentrada en un intervalo o una categoría?\n- ¿Outliers? $\\rightarrow$ Usa gráficas de `boxplot`.\n- Da preferencia a los `density plots`, en esta gráfica es más importante la forma que los valores actuales del eje vertical.\n- Si los datos están concentrados en un solo lado de la gráfica (`skewed`) y es no negativa es bueno representarla en `log10`.\n- Una grafica de barras no da más información que `summary()`, aunque algunos las prefieren.\n    - Es bueno mostrarla horizontal y ordenada.\n\n##### Dos variables\n\n- ¿Existe relación entre dos variables de entrada? ¿entre una entrada y la variable de salida?\n- ¿Qué tan fuerte?\n- ¿Qué tipo de relación?\n- `Scatter plot` entre dos variables numéricas, calcular la correlación de Pearson en un conjunto `sano` de los datos, visualizar la curva que mejor representa los datos.\n- `Stacked bar charts` para dos variables categóricas.\n    - Si quieres comparar razones a lo largo de las categorías lo mejor es usar un `filled bar chart`. En este caso se recomienda agregar un  `rug` para tener una idea de la cantidad de individuos.\n    - Si hay múltiples categorías por variable, es mejor usar `facets`.\n- Para variable categórica y numérica es recomendable usar `boxplot` (en su versión de `violin` o `jitter`).\n\n\n<div style=\"background-color:#ffcf40\">\n\nTarea 5 **Ejercicio**. Rmd y html en el git dentro de tu carpeta con el nombre tarea_5_eda. Se entrega máximo el **23 de octubre 2017 23:59:59 CST** (-0.5 por cada día de retraso). Enjoy! ╭(◔ ◡ ◔)/  \n\n- Es importante en la etapa de exploración, poder generar varias gráficas de manera automática \n  y simple para analizarlas visualmente y tener una idea de los datos. \n- Crea una función que genere los tipos de gráfica para cada par de variables del `data.frame` (en realidad es un `tibble`).\n  Esta función debe de recibir dos parámetros, uno que indique si genera todas las combinaciones \n  de dos variables o recibe una lista de variables en las cuales generar las combinaciones.\n- Guárdala en `utils.R`. \n- Crea en `03-eda.R` en ambas carpetas: `algas` y `german`.\n\n</div>\n\n#### Valores faltantes: `NAs`\n\n- Los pasos son los siguientes:\n    - Identificar los datos faltantes.\n    - Examinar las causas de los datos faltantes. \n        - Preguntar al domain expert, etc.\n    - Borrar los casos (o columnas) que contienen los `NAs` o reemplazar (imputar) los `NAs` con valores razonables -puedes ocupar modelos para imputar los NA's-\n    \n- La teoría la veremos más adelante en el curso.\n\n**NOTA**: Todas estás recomendaciones aplican igual para *outliers*\n\n- Es importante recordar que en `R` la operación `x == NA` nunca regresa `TRUE`, siempre hay que utilizar las funciones `is.na()`, `is.nan()` e `is.infinite()`.\n\n- El método `complete.cases` identifica los renglones (individuos) del `data.frame` que no tienen ningún `NA` en sus columnas (variables).\n\n- Es posible usar `sum` y `mean` con `is.na` para obtener el total por columna de faltantes y el porcentaje.\n    - ¿Por qué?\n\nAunque más adelante veremos técnicas más poderosas, vale la pena mencionar \nel ejemplo mostrado en `R in action`, cap. 15. \n\nLa técnica nos permite determinar si los faltantes en una variable están correlacionados con otra.\n\n```{r}\nx <- as.data.frame(abs(is.na(algas))) # df es un data.frame\n\nhead(x)\n\n# Extrae las variables que tienen algunas celdas con NAs\ny <- x[which(sapply(x, sd) > 0)] \n\n# Da la correación, un valor alto positivo significa que desaparecen juntas.\ncor(y) \n```\n\n\n**Tarea 6. Ejercicio 1**\n\n- Genera un reporte para ambos conjuntos de datos que indique el estado de los valores missing.\n- Muestra la matriz de correlación faltante en una gráfica.\n- ¿Qué puedes interpretar?\n\n#### **Remover observaciones**\n\nLas variables con más faltantes son Promedio de Cloruro `Cl` (10) y Promedio de Clorofila `Chla` (12).\n\n```{r}\nsummary(algas[-grep(colnames(algas),pattern = \"^a[1-9]\")]) # Nota el uso del grep\n```\n\nTambién se puede hacer con `dplyr`\n\n```{r eval=F}\nalgas %>%\n    select(-starts_with(\"a\")) %>%\n    summary()\n```\n\n\n![](../images/pointer.png) Antes de removerlas es recomendable verlos, guardarlos y contarlos:\n\n```{r}\nnrow(algas[!complete.cases(algas),])\n```\n\nHay `r nrow(algas[!complete.cases(algas),])` observaciones en las cuales tienen `NAs`\n\n```{r}\nalgas_con_NAs <- algas[!complete.cases(algas),]\n```\n\n**Siempre es bueno guardarlas** si se piensan eliminar del dataset, ¿por qué?\n\nLas observaciones con `NAs`son las siguientes (usaremos la función `print()` para explorar)\n\n```{r}\nalgas_con_NAs[c('max_PH', 'min_O2', 'Cl', 'NO3', 'NH4', 'oPO4', 'PO4', 'Chla')]  %>%\n    print(n = 33)\n```\n\nde los cuales, hay dos renglones que tienen más del `50%` (`6`) de \nlas variables independientes nulas.\n\n\nAunque remover las observaciones con `NAs` **NO** sea la estrategia, quitar las observaciones \ncon muchas columnas vacías, puede ser recomendable.\n\nEn los casos en los que no es posible hacer una explorarción visual, se puede utilizar el siguiente código\n\n```{r}\n# ¿Cuántos NAs hay por observación?\napply(algas, 1, function(x) sum(is.na(x)))\n```\n\nSi queremos ver las observaciones:\n\n```{r}\nalgas[apply(algas, 1, function(x) sum(is.na(x))) > 2,]\n```\n\nLo cual confirma nuestra exploración visual.\n\nSi eliminar las observaciones con `NAs` va a ser el camino que vamos a tomar, habrá que hacerlo de manera\nreproducible, lo que sigue es el código de la función `indices_con_NAs'\n\n```{r}\nindices_con_NAs\n```\n\n```{r}\nindices_con_NAs(algas, 0.2)\n```\n\n```{r}\nindices_con_NAs(algas, 0.8)\n```\n\n```{r, eval=FALSE}\n# Si queremos remover las que tengan más del 20% de NAs...\nalgas <- algas[-indices_con_NAs(algas, 0.2),]\ndim(algas)\n```\n\n#### **Renivelar** \n\n- Si la variable es categórica (`factor`), puedes crear una nueva variable y poner los `NA`s a un nuevo `level`, e.g. `missing`\n\n    - Por ejemplo, suponiendo que hubiese una variable categórica con faltantes en nuestros dataset\n  \n```{r eval=FALSE}\ndataset$cat_with_NAs_fix <- ifelse(is.na(dataset$cat_with_NAs),\n                              \"missing\",\n                              ifelse(dataset$ccat_with_NAs == TRUE,    \n                                                # o el valor que sea\n                                                \"level_1\",\n                                                \"level_2\"))\n```   \n\n- Sólo recuerda que es posible que el valor de `NA` signifique algo.\n\n- Esto también se puede hacer con variables numéricas, si primero las vuelves categóricas (i.e. *binning*)\n\n#### **Centralidad**\n\n- Una estrategia es rellenar los valores faltantes con alguna medida de centralidad.\n    - Media, mediana, moda, etc.\n\n- Para variables distribuidas normalmente, esta opción es la mejor.\n\n- Pero para variables *skewed*  o con *outliers* esta decisión puede ser desastrosa.\n\n- Por lo tanto, esta estrategia no se debe de utilizar salvo una exploración previa de las variables.\n\n**Tarea 6. Ejercicio 2**\n\n+ ¿A qué variables del set de datos de `algas` les puedes aplicar este procedimiento?\n+ ¿Qué puedes decir de `german_data`?\n+ A las variables que no se les puede aplicar, explica por qué no.\n\n- Esta decisión debe de ser reproducible, agrega a `utils.R` una función que impute \nen las variables con  `NAs` el valor central (`median` si es numérica, `moda` si es categórica).\nLa función debe de tener la siguiente firma:\n\n```{r, eval=FALSE}\nimputar_valor_central <- function(data, colnames) {...}\n```\n\n#### **Correlación**\n\nCalculando rápidamente la correlación\n\n```{r}\nalgas[,-c(1:3)] %>%\n    cor(use=\"complete.obs\") %>%\n    symnum()\n```\n\n\nObservamos que  `oPO4` y `PO4` están altamente relacionadas (`> 0.9`).\n\n\n```{r correlacion, warning=FALSE, fig.height=4, fig.width=8}\nggplot(data=algas) + \n  aes(x=oPO4, y=PO4) + \n  geom_point(shape=1) + # Usamos una bolita para los puntos\n  geom_smooth(method=lm, se=FALSE) +\n    theme_hc()\n  # Mostramos la linea de la regresión y no mostramos la región de confianza\n```\n\n```{r}\nalgas\n```\n\n```{r}\n#algas <- algas[-indices_con_NAs(algas, 0.2),]\nmodelo <- lm(PO4 ~ oPO4, data=algas)\nmodelo\n```\n\nEntonces la fórmula que relaciona el `PO4` con `oPO4` es\n\n$$\nPO4 = `r modelo$coefficients['(Intercept)']` + `r modelo$coefficients['oPO4']`*oPO4\n$$\n\n**Tarea 6. Ejercicio 3**\n\n+ Crea una función que sustituya los `NAs` con el valor dado por la \nregresión lineal recién calculada (No automatices la regresión lineal) usando la\nsiguiente firma\n\n```{r, eval=FALSE}\nimputar_valor_lm <- function(var_independiente, modelo) { ... }\n```\n\n#### **Similitud**\n\n- Podemos suponer que si dos observaciones son similares y una de ellas tiene `NAs` \nen alguna variable, hay una alta probabilidad de que esa variable tenga un valor\nsimilar al valor de esa variable en la otra observación.\n    - Obviamente es una suposición...\n    \n- Debemos definir la noción de similar\n    - Y esto significa definir un espacio métrico en el espacio que\n       usamos para describir las observaciones.\n    - Obviamente, otra gran suposición...\n\n- Para variables numéricas se puede usar la distancia euclídeana\n\n$$\nd(\\vec{x}, \\vec{y}) = \\sqrt{\\sum_{i=1}^p(\\vec{x}_i - \\vec{y}_i)}\n$$\n\n- Si son nominales las variables\n\n$$\nd(\\vec{x}, \\vec{y}) = \\sqrt{\\sum_{i=1}^p \\delta_i(\\vec{x}_i, \\vec{y}_i)}\n$$\n\ndonde $\\delta(\\vec{x},  \\vec{y})$ es la [delta de Kronecker](https://oeis.org/wiki/Kronecker_delta) ¿qué? (;-_-)\n\nLa dela de Kronecher identifica si dos variables nominales son iguales o no: \n\n$$\\delta = \\begin{cases} 1 & \\text{if } x=0 \\\\ 0 & \\text{if } x>0 \\end{cases}$$\n\nEjemplos: \n\n+ $\\delta_{100}^{100}=1$\n+ $\\delta_4^{134}=0$\n+ $\\delta_{-1}^{i\\pi}=1$\n+ $\\delta_{7,2^3-1,\\frac{21}{3}}=1$\n+ $\\delta_{-1}^{sin(2017 \\sqrt[6]{2})}=0$ \n\n\n+ Una vez definida la similitud, debemos de definir el valor que imputar al `NA`.\n+ Una opción es utilizar una medida de centralidad de los $k$ observaciones más cercanas. \n+ El Promedio con peso de los valores de los vecinos, es otra opción. El peso se puede determinar de varias\nmaneras, pero usar como *kernel* una función gaussiana.\n\n$$\npeso(d) = e^{-d}\n$$\n\ndonde $d$ es la distancia de una observación a la que estamos considerando.\n\n\n- Es importante *estandarizar* los valores numéricos antes de calcular las distancias.\n\n$$\n\\vec{x}_{normalizado} = \\frac{\\vec{x}_i - \\bar{x}}{\\sigma_{x}}\n$$\n\n![](../images/pointer.png) ¿Por qué?\n\n\n**Tarea 6. Ejercicio 4** \n\n- Implementa una función que impute por similitud con la firma\n\n```{r, eval=FALSE}\nimputar_por_similitud <- function(data, num_vecinos) { ... }\n```\n\n- Aplícalo a `algas` y `german`. \n- ¿Son muy diferentes las estadísticas ignorando los `NAs` comparadas con este método?\n\n\n#### **Transformación de datos** \n\nParéntesis cultural, en minería de datos: \n\n- Normalizar $$x_{nuevo}=\\frac{x-x_{min}}{x_{max}-x_{min}}$$\n- Estandarizar $$x_{nuevo}=\\frac{x-\\mu}{\\sigma}$$\n\n![](../images/pointer.png) Normalizar/estandarizar es útil cuando las cantidades absolutas son menos importantes que las relativas. \n\n\n- Normalizar y reescalar \n    - Usar la desviación estándar como unidad de medida.\n    - Tiene mucho sentido si la distribución es simétrica.\n    - Si no lo es, es posible que sea *lognormally distributed* \n     (como el ingreso monetario o los gastos), una transformación `log10()`\n     lo hará útil.\n- Es una buena idea usar `log` si el rango de tus datos cubre varios ordenes de magnitud. \n    - Regularmente, estas variables vienen de procesos **multiplicativos** en lugar de aditivos. \n\n- Si el rango incluye cantidades negativas, usa (crea) una función `signedLog10`\n\n```{r eval=FALSE}\nsignedLog10 <- function(x) {\n  ifelse(abs(x) <= 1.0, sign(x)*log10(abs(x)))\n}\n```\n\n**Tarea 6, Ejercicio 5**\n\n- Este es un buen momento para dejar de duplicar código y concentrar \n  todas las funciones de `utils.R` que se puedan reutilizar en un archivo `toolset.R`.\n  Ajusta tus demás archivos de acuerdo a este cambio -si aplica- \n- Crea un `R notebook` para cada *dataset* utilizando los archivos reproducibles y el archivo\n  `toolset.R`. Incluye en estos `notebook` la estructura de los datos, *GEDA* transformaciones de los datos \n  y observaciones pertinentes (como *outliers*, estructura de los datos faltantes). \n  Explica los métodos de imputación que usaste (si fué necesario) y porqué los usaste.\n\n\n#### EDA $\\to$ modelado\n\n- En general la exploración de datos se divide en tres pasos:\n    - Verificar la distribución de las variables individuales\n        - Identificando *outliers*, valores faltantes $\\to$ transformación, eliminación del *dataset*, etc.\n    - Verificar la relación entre las variables dependientes y los predictores \n        - Se podrá usar en `feature selection`\n    - Relación entre los predictores\n        - Eliminación de variables redundantes\n\n\n### Titanic\n\n#### Datos relacionales y la cuestión de la Semántica\n\n![Titanic](../images/titanic.jpg)\n\n```{r eval=F, message=FALSE, warning=FALSE, include=FALSE}\ninstalar <- function(paquete) {\n\n    if (!require(paquete,character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)) {\n        install.packages(as.character(paquete), dependecies = TRUE, repos = \"http://cran.us.r-project.org\")\n        library(paquete, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)\n    }\n}\n\npaquetes <- c('lubridate', 'magrittr', 'ggvis', 'dplyr', 'tidyr', 'readr', 'rvest', \n              'ggplot2', 'stringr', 'ggthemes', 'googleVis', 'shiny', 'tibble', 'vcd', 'vcdExtra',\n              'GGally', 'readODS', 'readxl', \"RSQLite\")\n\nlapply(paquetes, instalar)\n```\n\n```{r warning=F, error=F, message=F}\ntitanic_path <- '../data/Titanic/titanic.ods'\n\nds_names <- ods_sheets(titanic_path)\nds_names\n```\n\nArreglemos los nombres de los *data sets*\n\n```{r}\nclean_sheet_name <- function(sheet_name) {\n    str_replace_all(str_replace_all(string=sheet_name, pattern=\" \", replace=\"_\"), pattern=\"'\", replace=\"\") %>% \n    str_to_lower()\n}\n\nsapply(ds_names, clean_sheet_name)\n```\n\nAhora obtenemos los *datasets* y los guardamos\n\n```{r echo=T, warning=F, message=F, error=F}\nsave_sheet <- function(sheet_name) {\n    file_name <-  paste0(\"../data/Titanic/\", clean_sheet_name(sheet_name), \".rds\")\n    saveRDS(object = read_ods(titanic_path, sheet = sheet_name), file = file_name)\n}\n\n\nlapply(ods_sheets(titanic_path), save_sheet)\n```\n\n\nCargar los datos: \n\n```{r}\nrm(list=ls())\n\nrds_files <- dir(\"../data/Titanic/\", pattern = \"*.rds\", full.names = TRUE)\n\n#lapply te devolverá las cosas en un lista... una lista de dataframes :)\nds <- lapply(rds_files, read_rds)\nclass(ds)\nclass(ds[[1]])\n#cuantos dataframes contiene esta lista? \nlength(ds)\n\n#basename elimina todo el path del nombre excepto la última parte (se quedará con la extensión del archivo!), ?basename\nnames(ds) <- lapply(rds_files, basename)\nnames(ds)\n```\n\n1. En algunos *data sets* se agregaron columnas de más, remuévelas\n\n```{r}\n#veamos qué nombres tiene cada dataframe\nlapply(ds, names)\n\n#si quisieramos obtener los conjuntos de nombres únicos\nlapply(ds, names) %>% unique()\n```\n\nVemos que hay 4 tipos de listas de nombres diferentes: \n\n+ Las que tienen la últimas columna con un espacio de nombre y la penúltima sin nombre\n+ Las que no tienen columnas demás\n+ Las que de plano no tienen nombres\n+ Las que tienen las últimas dos columnas sin nombre -sutil diferencia con el primer caso- \n\nAverigüemos más: \n\n```{r}\nlapply(ds, head)\n```\n\nEl data frame `discharged_crew.rds` tiene dos columnas que no tienen nombre y parecen contener el nombre del empleado, el oficio y la razón de su salida como empleado del barcof. Quitemos este data frame de nuestro set de datos\n\n```{r}\nds <- ds[-which(lapply(lapply(ds, names), length) == 2)]\n```\n\n2. Juntemos los data frames en uno solo y quitemos las columnas que están demás\n\nObtengamos el número mínimo de nombres como base (los demás tienen columnas vacías)\n```{r}\nnum_cols <- lapply((lapply(ds, names)), length) %>% unlist() %>% min()\nnum_cols \n```\n\nPero... primero revisemos que los tipos de datos son los mismos -no vaya a ser-\n```{r}\nlapply(ds, str)\n```\n\n(╯°□°)╯︵ ┻━┻   Era demasiado bello para ser real! `Age` y `Body` en algunos *dataframes* son `int` en algunos son `chr`... no los podemos juntar si son de diferentes tipos cambiemos a `chr` todas las columnas por facilidad\n\n```{r}\nds <- lapply(ds, function(x) lapply(x, as.character))\n#verifiquemos \nlapply(ds, str)\n```\n\n\n```{r}\n#bind_rows es como rbind solo que optimizado por Hadley Wickham :) \ntitanic <- bind_rows(ds)[, 1:num_cols]\n```\n\nCambiemos nombres a minúmsculas y sin simbolillos raros `/`\n```{r}\nnames(titanic) <- str_replace_all(names(titanic), \"/| \", \"_\") %>% \n  str_to_lower()\nnames(titanic)\n```\n\nPasemos el dataframe a un objeto más eficiente\n```{r}\ntitanic <- tbl_df(titanic)\ntitanic\n```\n\n\n3. Genera las siguientes variables: `survived`, `name`, `last_name`, `sex` [](../images/pointer.png) ¿Se te ocurre alguna forma de definir `survived`?\n4. Arregla la columna de precio, edad $\\rightarrow$ como verás en aquellos ayeres el dinero no tenía decimales... aquí nos puede ayudar Michael :P [British money](http://projectbritain.com/moneyold.htm). Por otro lado, en la columna edad hay niños con menos de 1 año expresados con el número de meses seguido de `m`...\n\nHaremos el 3 y el 4 juntos :) \n\n```{r}\ntitanic <- titanic %>% \n  separate(name, into=c(\"last_name\", \"name\"), sep=\",\", extra=\"drop\") %>%\n  separate(fare, into=c(\"pounds\", \"shillings\", \"pence\"), sep=\" \", extra=\"drop\") %>%\n  separate(age, into=c(\"age\", \"units\"), sep=2, extra=\"drop\") %>%\n  mutate(sex=ifelse(grepl(\"Miss|Mrs|Mme.|Lady|Doña|Ms\", name), 'F',\n                      ifelse(grepl(\"Mr|Sir|Sig|Dr|Master|Captain|Major|Rev.|Colonel|Fr|Don.\", name), 'M', NA))) %>% \n  mutate(boat_location=ifelse(as.integer(boat) %in% c(9:16), 'Popa', \n                              ifelse(boat %in% c(LETTERS[1:4]) | as.integer(boat) %in% c(1:8), 'Proa', NA))) %>% \n  mutate(age=ifelse(units == \"m\", 1, as.integer(age))) %>% \n  mutate(survived=!is.na(boat)) %>%\n  dplyr::select(-c(shillings, pence, body, units)) %>%\n  mutate(pounds=str_replace(pounds, \"£\", \"\") %>% as.integer()) %>%\n  mutate(class_dept=as.factor(class_dept), group=as.factor(group), ship=as.factor(ship),\n         joined=as.factor(joined), job=as.factor(job), boat=as.factor(boat),\n         sex=as.factor(sex), boat_location=as.factor(boat_location))\n  \n```\n\nQue bonito es `dplyr` y `tidyr` (ﾉ^_^)ﾉ\n\n```{r}\nsummary(titanic)\n```\n\n5. Agrega una columna de `age` que sea categórica. Definamos 3 categorías: \n\n+ **infante:** si es menor de 18 años\n+ **adulto:** entre 18 y 65 años\n+ **adulto mayor:** si es mayor a 65 años\n\n```{r}\ntitanic <- titanic %>% mutate(age = ifelse(age <= 18, \"infante\",\n                                           ifelse(age > 65, \"adulto mayor\", \n                                                  \"adulto\")))\n#verifiquemos\ntitanic\n```\n\n\n6. Ajusta a precios del día de hoy (Por ejemplo usa esta [página](http://inflation.stephenmorley.org/)) ¿En que clase hubieras viajado? ¿Cuál era tu probilidad de supervivencia?\n\n```{r}\nggplot(titanic, aes(pounds)) + \n  geom_histogram(binwidth = 30, na.rm=T) +\n  theme_bw()\n\n\ntitanic <- titanic %>% \n    group_by(ticket) %>% \n    mutate(pounds_per_ticket = round(pounds/n())) %>% \n  ungroup()\n\ntitanic\n\ntitanic %>% filter(class_dept %in% c('1st Class', '2nd Class', '3rd Class')) %>%\n  ggplot(aes(pounds_per_ticket)) + \n  geom_histogram(binwidth = 10) + \n  facet_grid(class_dept~., scales = \"free_y\") +\n  theme_bw()\n```\n\n$\\rightarrow$ Aproximadamente 10 libras de 1912 son 1,080 libras actuales, 50 libras son 5,400 y 100 libras son 10,800 libras al 2017\n\n7. Observando la distribución de botes que se muestra en la figura ¿Qué puedes decir sobre como se utilizaron?\n  ¿Coincide con la película de Titanic de James Cameron?\n\n![](../images/deck_plan_titanic.jpg)\n\n```{r}\ntitanic %>% \n    group_by(boat_location) %>% \n    summarise(n=n())\n```\n\nEso no dice mucho...\n\n```{r}\ntitanic %>%\n    group_by(boat) %>%\n    summarise(n=n()) %>%\n    arrange(desc(n))\n```\n\nLos botes del 1 al 16 tenían una capacidad de 65 personas, los botes del **A** al **D** tenían una capacidad de 45 personas. ([Fuente](https://en.wikipedia.org/wiki/RMS_Titanic)).\n\nFuente de los datos: \n\n[Encyclopedia Titanica](https://www.encyclopedia-titanica.org/)\n\n### Berka\n\n```{r eval=F}\ninstalar <- function(paquete) {\n\n    if (!require(paquete,character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)) {\n        install.packages(as.character(paquete), dependecies = TRUE, repos = \"http://cran.us.r-project.org\")\n        library(paquete, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)\n    }\n}\n\npaquetes <- c('lubridate', 'magrittr', 'ggvis', 'dplyr', 'tidyr', 'readr', 'rvest', \n              'ggplot2', 'stringr', 'ggthemes', 'googleVis', 'shiny', 'tibble', 'vcd', 'vcdExtra',\n              'GGally', 'readODS', 'readxl', \"RSQLite\")\n\nlapply(paquetes, instalar);\n```\n\nLos datos están en `http://sorry.vse.cz/~berka/challenge/pkdd1999/data_berka.zip`, descárgalos y \nguárdalos en `data/berka`, fueron usados en la competencia de [PKDD de 1999](http://lisp.vse.cz/pkdd99/). \n\n#### Meta\n\n\"El banco busca mejorar sus servicios, Por ejemplo, los admnistradores del banco \ntienen únicamente una vaga idea de quién es un buen cliente (al cual ofrecerle\nmás servicios) y quién es un mal cliente (alguien al que hay que cuidar para \nminimizar las pérdidas del banco). Afortunadamente, el banco almacena datos \nde sus clientes, sus cuentas (transacciones), préstamos que ya se otorgaron, \ntarjetas de crédito dadas. Los administradaores del banco esperan mejorar\nsu entendimiento de los clientes y mejorar así sus servicios. Una mera aplicación\nde una herramienta de *discovery* no los va a convencer.\"\n\n\n#### Esquema\n\n##### Account\n\nCaracterísticas de la cuenta\nArchivo: `account`\n\n Column|Description|Notes\n--------|------------|-----------------------|\naccount_id\t|Identification of the account|\ndistrict_id\t|Location of the branch\t |\ndate\t|Date of the account's creation\t|In the form: YYMMDD \nfrequency\t|Frequency of statement issuance|\t\"POPLATEK MESICNE\" - Monthly Issuance\n| | |\"POPLATEK TYDNE\" - Weekly Issuance\n| | | \"POPLATEK PO OBRATU\" - Issuance After Transaction\n\n\n##### Client\n\nCaracterísticas del cliente\nArchivo: `client`\n\nColumn\t|Description|\tNotes\n--------|------------|---------------------------|\nclient_id\t|Client Identifier\t |\nbirth number\t|Birthday and Sex |\tThe value is in the form: YYMMDD (for men)\n| | | The value is in the form: YYMM+50DD (for women)\n| | |Where YYMMDD is the date of birth\ndistrict_id\t|Address of the client\t |\n\n\t\n\n##### Disposition \n\nRelaciona una cuenta con un cliente (los derechos  de los clientes para\noperar cuentas)\nArchivo: `disp`\n\nColumn\t|Description\t|Notes\n--------|------------|-----------------------------------|\ndisp_id\t|Record Identifier\t |\nclient_id\t|Client Identifier|\t \naccount_id\t|Account Identifier\t |\ntype\t| Type of Disposition (owner/user)\t|Only owner can issue permanent orders and ask for a loan\n\n##### Loan\n\nPréstamos dabos a una cuenta\nArchivo: `loan`\n\nColumn\t|Description\t|Notes\n--------|------------|-----------------------------------|\ndisp_id\t|Record Identifier\t |\nloan_id\t|Record Identifier\t |\naccount_id\t|Account Identifier\t |\ndate\t|Date when loan was granted\t|In the form: YYMMDD\namount\t|Amount of Loan\t |\nduration\t|Duration of Loan\t |\npayments\t|Monthly Payments on Loan\t |\nstatus\t|Status in paying off the loan\t|'A' stands for contract finished, no problems\n| | | 'B' stands for contract finished, loan not payed\n| | | 'C' stands for running contract, OK thus-far\n| | | 'D' stands for running contract, client in debt\n\n##### Order\n\nCaracterísticas de una orden de pago\nArchivo: `order`\n\nColumn\t|Description\t|Notes\n--------|------------|--------------------------------|\norder_id\t|Record Identifier\t |\naccount_id\t|Account the order is issued for\t |\nbank_to\t|Bank of the recipient\t|Each bank has a unique two-letter code\naccount_to|\tAccount of the recipient\t |\namount\t|Amount debited from order account |\t \nK_symbol|\tCharacterization of the payment|\t'POJISTNE' stands for Insurance Payment\n| | |'SIPO' stands for Household Payment\n| | |'LEASING' stands for Leasing Payment\n| | | 'UVER' stands for Loan Payment\n\n##### Transaction\n\nTransacciones en las cuentas\nArchivo: `trans`\n\nColumn\t|Description\t|Notes\n--------|------------|---------------------------|\ntrans_id |\tRecord Identifier\t |\naccount_id\t|Account the transaction is issued on\t |\ndate\t|Date of transaction\t|In the form: YYMMDD\ntype\t|debit/credit transaction\t|'PRIJEM' stands for Credit\n| | | 'VYDAJ' stands for Debit (withdrawal)\noperation\t|Mode of Transaction\t|'VYBER KARTOU' stands for Credit Card Withdrawal\n| | |'VKLAD' stands for Credit in Cash\n| | |'PREVOD Z UCTU' stands for Collection from Another Bank\n| | |'VYBER' stands for Withdrawal in Cash\n| | | 'PREVOD NA UCET' stands for Remittance to Another Bank\namount\t|Amount of Transaction\t |\nbalance\t|Balance of Account after Transaction\t |\nK_Symbol\t|Characterization of Transaction\t|'POJISTNE' stands for Insurance Payment\n| | |'SLUZBY' stands for Payment of Statement\n| | |'UROK' stands for Interest Credited\n| | |'SANKC. UROK' stands for Sanction Interest if Negative Balance\n| | |'SIPO' stands for Household Payment\n| | |'DUCHOD' stands for Old-age Pension Payment\n| | |'UVER' stands for Loan Payment\nbank\t|Bank of the partner\t|Each bank has unique two-letter code\naccount\t|Account of the partner\t |\n\n##### Demographic\n\nCaracterísticas  de un distrito\nArchivo: `district`\n\n\nColumn\t|Description\t|Notes\n--------|------------|----------------------|\nA1 | district_id|\tDistrict Identifier\t \nA2\t|District Name\t \nA3\t|Region\t \nA4\t|No. of Inhabitants\t \nA5\t|No. of Municipalities with inhabitants < 499\t \nA6\t|No. of Municipalities with inhabitants 500-1999\t \nA7\t|No. of Municipalities with inhabitants 2000-9999\t \nA8\t|No. of Municipalities with inhabitants > 10000\t \nA9\t|No. of Cities\t \nA10\t|Ratio of urban inhabitants\t \nA11\t|Average Salary\t \nA12\t|Unemployment rate in 1995\t \nA13\t|Unemployment rate in 1996\t \nA14\t|No. of Enterpreneurs per 1000 inhabitants\t \nA15\t|No. of Crimes commited in 1995\t \nA16\t|No. of Crimes commited in 1996\n\n##### Credit card\n\nTarjeta de crédito otorgada a una cuenta\nArchivo: `card` \n\nColumn\t|Description\t|Notes\n--------|------------|--------------------------|\ncard_id\t|Card Identifier\t |\ndisp_id\t|Disposition to an account\t |\ntype\t|Type of card\t|Types are 'Junior', 'Classic', and 'Gold'\nissued\t|Date card was issued\t|In the format: YYMMDD\n\n#### Características importantes\n\n- Cada cuenta tiene características estáticas (`account`) y dinámicas\n(pagos, créditos, balances) dados en `order` y `transaction`\n- `client` características de personas que pueden manipular cuentas. \n- Los clientes pueden tener varias cuentas, y viceversa. La relación entre clientes y cuentas está en `disposition`\n- Los servicios del banco están descritos en `loan` y `credit_card`\n- Una cuenta puede tener varias **tdc**\n- Máximo un préstamo se le puede otorgar a una cuenta.\n- La tabla de demografía contiene informacióń sobre los distritos, se puede\ndeducir información adicional sobre los clientes a partir de esta tabla.\n\n#### Esquema Entidad-Relación\n\n![Berka dataset](http://lisp.vse.cz/pkdd99/Challenge/data.gif)\n\n#### Base de datos\n\nLa utilización de una base de datos (Relacional, Grafos, Columnar, etc), siempre es recomendable sobre \nel uso de archivos (la excepción es un Apache Hadoop, pero eso lo veremos en Métodos de Gran Escala ╭(◔ ◡ ◔)/).\n\nLas ventajas de la utilización de una base de datos son las siguientes:\n\n- Es posible manejar volúmenes de datos más grandes que memoria.\n- Velocidad de acceso a los datos\n- Facilidad de manipulación con lenguajes relacionales (como `SQL`)\n- Colaboración\n    - Varias personas pueden accesar a los datos\n    - Estas personas no tienen por qué usar el mismo lenguaje (!)\n\nUsaremos `sqlite3`  para este ejemplo. `SQLite` es una base de datos relacional, local\n(por lo que algunas de las ventajas recién mencionadas no aplican ¿Cuál?)\n\n+ Instalar SQLite3 en Ubuntu 16.04: \n\n```{shell eval=FALSE}\nsudo apt-get update\nsudo apt-get install sqlite3\n```\n\n+ Instalar SQLite3 en MAC: si tienes OS Leopard en adelante, no necistas instalarlo, ya viene. Si tienes un OS más viejito [Mac y Windows](https://mislav.net/rails/install-sqlite3/) -nunca lo he hecho!-\n\n+ [SQLite3 CLI](https://sqlite.org/cli.html)\n\n*NOTA: Lo que sigue ocurre en la línea de comandos*\n\nPara abrir una base de datos `sqlite` en memoria\n\n```{shell eval=FALSE}\n$ sqlite3\nSQLite version 3.13.0 2016-05-18 10:57:30\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\nsqlite> \n```\n\n```{shell eval=FALSE}\n## Emebelliciendo el output\nsqlite> .header on\nsqlite> .mode column\n\n\n## Importar archivos (accounts.asc) a la base de datos a la tabla (accounts)\n## ¡Usa plural para las tablas!\nsqlite> .separator \";\"\nsqlite> .import account.asc accounts\n\n## Verifica que la tabla exista\nsqlite> .tables\nacccounts\n\n## Estructura de la tabla\nsqrlite> PRAGMA table_info(accounts);\ncid         name        type        notnull     dflt_value  pk        \n----------  ----------  ----------  ----------  ----------  ----------\n0           account_id  TEXT        0                       0         \n1           district_id TEXT        0                       0         \n2           frequency   TEXT        0                       0         \n3           date        TEXT        0                       0    \n\n## veamos qué hay adentro\nsqrlite> select * from accounts limit 5;\naccount_id  district_id  frequency         date      \n----------  -----------  ----------------  ----------\n576         55           POPLATEK MESICNE  930101    \n3818        74           POPLATEK MESICNE  930101    \n704         55           POPLATEK MESICNE  930101    \n2378        16           POPLATEK MESICNE  930101    \n2632        24           POPLATEK MESICNE  930102  \n\n## Guardar la tabla\nsqlite> .save berka.raw\n```\n\nLa siguiente vez que quieras consultar la base de datos\n\n```{shell eval=FALSE}\n$ sqlite3 berka.raw\nSQLite version 3.11.0 2016-02-15 17:29:24\nEnter \".help\" for usage hints.\nsqlite> \n```\n\nO si se te olvida poner el nombre del archivo:\n\n```{shell eval=FALSE}\n$ sqlite3\nSQLite version 3.11.0 2016-02-15 17:29:24\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\nsqlite> .open berka.raw\n```\n\n**Ejercicio: To Raw**\n\nCargaremos los datos en `berka.raw`\n\n```{shell eval=FALSE}\nfor db in *asc;\ndo\ntable=${db%.*}s\nif [ \"$db\" = \"trans.asc\" ]; then\ntable=\"transactions\"\nfi\necho -e \".separator ';'\\n.import ${db} ${table}\" | sqlite3 berka.raw \ndone\n```\n\nPuedes conectarte a tu base de sqlite con [dplyr](http://dplyr.tidyverse.org/reference/src_dbi.html) , necesitarás el paquete `RSQLite`\n\n```{r}\nlibrary(RSQLite)\n\nberka_db <- src_sqlite(path=\"~/Documents/itam/introduction_to_ds/intro_to_ds/data/berka/berka.raw\", \n           create=FALSE)\ndb_list_tables(berka_db$con)\n\naccounts_tbl <- tbl(berka_db, \"accounts\")\nclients_tbl <- tbl(berka_db, \"clients\")\ndispositions_tbl <- tbl(berka_db, \"disps\")\n\naccounts_tbl %>% group_by(district_id) %>%\n  summarise(count=n()) %>% \n  arrange(desc(count)) %>%\n  collect()\n```\n\n**Ejercicio: Raw to Clean**\n\n1. Verifica que cada `account` tenga un `owner`\n\nEn la tabla disposition viene el atributo `type` que puede tener 2 valores distintos: `OWNER` y `DISPONENT`\n\n```{shell eval=FALSE}\nsqlite3> select distinct(type) \nfrom disps;\n```\n\nO en dplyr: \n```{r}\ndispositions_tbl %>% distinct(type) %>% collect()\n```\n\n\n```{shell eval=FALSE}\nsqlite3> select *, count(*)\nfrom disps\nwhere type = 'ONWER'\ngroup by account_id\nhaving count(*) > 1\norder by count(*) desc\nlimit 5;\n```\n\n```{r}\ndispositions_tbl %>% filter(type == 'OWNER') %>% \n  group_by(account_id) %>% \n  summarise(n=n()) %>%\n  arrange(desc(n)) %>% collect()\n```\n\n- Los registros de  `orders` y `loans` están duplicados en `transactions`. Es decir\nlos regsitros de `order`y `loan` están dentro de  `transactions` (por ejemplo, \nLos registros de `loan` en `tran` están identificados por el `k_symbol` `LP`)\n\n\n- Traduce los campos del checo al inglés.\n- En `client` cambia `BirthNumber` a `sex` y `age`\n- Discretiza `age` en `Youth` (0-24), `Adult` (25-45), `Middle-age` (46-64) y `Senior` (> 65)\n- En `disposition` cambia de `Dispondent` -> `User` \n- En `loan` discretiza usando alguna heuristica `amount`, `duration`  y `payments`\n- En `transaction` traduce la columna `type`, `operation`, `k_symbol`\n- Ajustamos los nombres de las tablas a plural, los `*_id` a singular.\n- Guardemos los datos en `berka.clean`\n\n### Limpieza retos técnicos\n\nImágenes tomadas de [TAMR](https://www.tamr.com/)\n\n![](../images/tamr_a.png)\n\n<br>\n\n![](../images/tamr_b.png)\n\n<br>\n\n![](../images/tamr_c.png)\n\n<br>\n\n![](../images/tamr_d.png)\n\n<br>\n\n![](../images/tamr_e.png)\n\n<br>\n\n![](../images/tamr_f.png)\n\n\n#### Primer acercamiento a **Linage and Procedence**: Columnas de procedencia -te recomiendo leer este [blog](https://blog.datank.ai/data-lineage-the-history-of-your-data-ebe1c143d608)-\n\n\nUn aspecto que siempre es olvidado, o que no se considera importante debido a los blogs, es el versionado de control de los datos\n\nEsto se puede implementar, agregando columnas para indicar de donde vienen los datos, o con qué procedimiento de limpieza se generaron, etc.\n\nSe puede utilizar el mismo id del código del ETL guardado en github.\n¿Cómo implementarías esto? ¿Puedes trazar de dónde provienen tus datos?",
    "created" : 1510198244207.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2017154854",
    "id" : "DB16087",
    "lastKnownWriteTime" : 1509498901,
    "last_content_update" : 1509498901,
    "path" : "C:/Users/FORANEA110/Desktop/MINERIA/Tareas/eda_clase_LILIANA_MILLAN/eda.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}